{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1c7f0e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import lightning as L\n",
    "\n",
    "\n",
    "class RPSDataModule(L.LightningDataModule):\n",
    "    def __init__(\n",
    "        self,\n",
    "        train_batch_size,\n",
    "        predict_batch_size,\n",
    "        train_data_dir=None,\n",
    "        val_data_dir=None,\n",
    "        test_data_dir=None,\n",
    "        predict_data_dir=None,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.train_batch_size = train_batch_size\n",
    "        self.predict_batch_size = predict_batch_size\n",
    "\n",
    "        self.train_data_dir = train_data_dir\n",
    "        self.val_data_dir = val_data_dir\n",
    "        self.test_data_dir = test_data_dir\n",
    "        self.predict_data_dir = predict_data_dir\n",
    "\n",
    "    def setup(self, stage):\n",
    "        if stage == \"fit\":\n",
    "            self.train_dataset = init_dataset(self.train_data_dir)\n",
    "            self.val_dataset = init_dataset(self.val_data_dir)\n",
    "        elif stage == \"validate\":\n",
    "            self.val_dataset = init_dataset(self.val_data_dir)\n",
    "        elif stage == \"test\":\n",
    "            self.test_dataset = init_dataset(self.test_data_dir)\n",
    "        elif stage == \"predict\":\n",
    "            self.predict_dataset = init_predict_dataset(self.predict_data_dir)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        return init_dataloader(self.train_dataset, self.train_batch_size, shuffle=True)\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        return init_dataloader(self.val_dataset, self.predict_batch_size, shuffle=False)\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        return init_dataloader(self.test_dataset, self.predict_batch_size, shuffle=False)\n",
    "\n",
    "    def predict_dataloader(self):\n",
    "        return init_dataloader(self.predict_dataset, self.predict_batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4038fa5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RPSModule(L.LightningModule):\n",
    "    def __init__(self, feature_extractor, num_classes=3, learning_rate=1e-3):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "\n",
    "        self.feature_extractor = feature_extractor\n",
    "        self.classifier = CatBoostClassifier(\n",
    "            task_type=\"GPU\",\n",
    "            iterations=2000,\n",
    "            random_state=42,\n",
    "            silent=True,\n",
    "        )\n",
    "\n",
    "        self.learning_rate = learning_rate\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        # Freeze feature extractor\n",
    "        for param in self.feature_extractor.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        # Initialize lists to store features and labels\n",
    "        self.train_features = []\n",
    "        self.train_labels = []\n",
    "        self.val_features = []\n",
    "        self.val_labels = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        features = self.feature_extractor(x)\n",
    "        return features\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        features = self(x)\n",
    "\n",
    "        # Store features and labels for classifier training\n",
    "        self.train_features.extend(features.cpu().numpy())\n",
    "        self.train_labels.extend(y.cpu().numpy())\n",
    "\n",
    "        return {\"loss\": torch.tensor(0.0, requires_grad=True)}  # Dummy loss\n",
    "\n",
    "    def on_train_epoch_end(self):\n",
    "        # Train CatBoost classifier on accumulated features\n",
    "        if self.train_features and self.train_labels:\n",
    "            self.classifier.fit(np.array(self.train_features), np.array(self.train_labels))\n",
    "\n",
    "            # Clear stored features and labels\n",
    "            self.train_features.clear()\n",
    "            self.train_labels.clear()\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        features = self(x)\n",
    "\n",
    "        # Store features and labels for validation\n",
    "        self.val_features.extend(features.cpu().numpy())\n",
    "        self.val_labels.extend(y.cpu().numpy())\n",
    "\n",
    "        return features\n",
    "\n",
    "    def on_validation_epoch_end(self):\n",
    "        # Validate using CatBoost classifier\n",
    "        if self.val_features and self.val_labels:\n",
    "            val_pred = self.classifier.predict(np.array(self.val_features))\n",
    "            val_acc = accuracy_score(np.array(self.val_labels), val_pred)\n",
    "\n",
    "            self.log(\"val_acc\", val_acc, prog_bar=True)\n",
    "\n",
    "            # Clear stored features and labels\n",
    "            self.val_features.clear()\n",
    "            self.val_labels.clear()\n",
    "\n",
    "    def predict_step(self, batch, batch_idx, dataloader_idx=0):\n",
    "        x, y = batch\n",
    "        features = self(x)\n",
    "        predictions = self.classifier.predict_proba(features.cpu().numpy())\n",
    "        return predictions, y\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # Since we're using CatBoost as classifier, we don't need PyTorch optimizer\n",
    "        # But Lightning requires at least one optimizer\n",
    "        return optim.Adam(self.parameters(), lr=self.learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rock-paper-scissors-classifier",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
